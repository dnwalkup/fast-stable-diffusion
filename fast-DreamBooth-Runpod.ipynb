{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32mInitial setup complete, variables set, please move on to the next cell !\n"
     ]
    }
   ],
   "source": [
    "############################################################# Dreambooth 4 Kaggle Mk2 ##############################################################\n",
    "#\n",
    "# Based on u/Yacben's (https://github.com/TheLastBen/fast-stable-diffusion)\n",
    "# Adapated for Kaggle by u/shutonga (https://github.com/tuwonga/fast_Dreambooth_4_kaggle)\n",
    "# Mk2 by u/_rundown_\n",
    "#\n",
    "#\n",
    "# ** NOTE: Each of these code blocks must be run in order to complete the training of your model. **\n",
    "#\n",
    "# ** NOTE: Unless you know what you're doing, follow the guidance and you shouldn't have issues. **\n",
    "#\n",
    "#\n",
    "#\n",
    "#------------------------------------------------------------- UPLOAD TRAINING IMAGES -------------------------------------------------------------#\n",
    "# Let's add your training images.\n",
    "#\n",
    "#\n",
    "# Step 1 - Prepare your images\n",
    "#\n",
    "# ** NOTE: Skip to \"Step 2 - Upload your images\" if your images are already prepped.\n",
    "#\n",
    "# For training a person:\n",
    "# Use 10 or 20 images. 50% close-up/face, 30% medium/torso, 20% long/wide.\n",
    "#\n",
    "# For training a style:\n",
    "# Use 100 images. 70% people, 20% landscapes, 10% animals/objects. \n",
    "#\n",
    "# Sizing:\n",
    "# Make sure your images are PNG format. 512 x 512 is currently ideal.\n",
    "#\n",
    "# It is highly recommended to use a service like https://www.birme.net to resize and manually crop the focus area of your images, however, \n",
    "# the program below incldues an image cropping tool which will crop to the center of your images.\n",
    "#\n",
    "# Naming:\n",
    "# Rename the instance picture to the same instance unique identifier for each subject. This will be your trigger prompt in Stable Diffusion \n",
    "# to activate your person/style.\n",
    "#\n",
    "# Naming example:\n",
    "# If you have 20 pictures of yourself, simply select them all and rename only one to the chosen identifier: (e.g. phtmejhn)\n",
    "# Assuming you're on Windows, the files would resultantly be: phtmejhn (1).jpg, phtmejhn (2).png ... etc.\n",
    "#\n",
    "# Check out this example: https://i.imgur.com/d2lD3rz.jpeg\n",
    "#\n",
    "# Multiple subjects:\n",
    "# If you're training with multiple subjects (e.g. another 20 images of a different person) do the same renaming procedure \n",
    "# for other people or objects with their unique identifier.\n",
    "#\n",
    "#\n",
    "# Step 2 - Upload your images\n",
    "#\n",
    "#\n",
    "# ** NOTE: For more information, see Nitrosocke's great guide: https://github.com/nitrosocke/dreambooth-training-guide **\n",
    "#\n",
    "#\n",
    "#\n",
    "#---------------------------------------------------------------- GLOBAL VARIABLES ----------------------------------------------------------------#\n",
    "# You've got your images uploaded, you're settings are locked in, time to start this 'ish.\n",
    "#\n",
    "# Let's set some global variables that are important for the training of your model.\n",
    "#\n",
    "#\n",
    "# ** NOTE: Best not to use spaces.\n",
    "#\n",
    "#\n",
    "\n",
    "Huggingface_Token = \"\"\n",
    "# Downloading the Stable Diffusion model\n",
    "# ** NOTE: Leave EMPTY if you're using the v2 model **\n",
    "\n",
    "# To download the Stable Diffusion v1.5 checkpoint, a Hugging Face account is required and you must\n",
    "# accept the terms in https://huggingface.co/runwayml/stable-diffusion-v1-5\n",
    "\n",
    "# In your account settings > access tokens (https://huggingface.co/settings/tokens), you can create a new token. Then copy and paste it above\n",
    "# between the parenthesis.\n",
    "\n",
    "Model_Version = \"V2-768px\"\n",
    "# \"1.5\", \"V2-512px\", \"V2-768px\"\n",
    "\n",
    "Session_Name = \"ilya_768\"\n",
    "# Name your session. If it already exists, it will load it to continue.\n",
    "\n",
    "Training_Type = \"style\"\n",
    "# Current options are: person or style. Insert word in the quotes.\n",
    "\n",
    "Class_Token = True\n",
    "# Class token is a part of your activation prompt. True or False. If true, your class token will be the same as your Training Type.\n",
    "\n",
    "PT = \"ilyaart\"\n",
    "# Prompt token. This is what you'll add to your SD prompt to activate your style/person  \n",
    "\n",
    "Crop_images = False\n",
    "# Do you want the app to manually crop your images? True or False. Default is False (recommended you follow the above directions).\n",
    "\n",
    "Crop_size = \"768\"\n",
    "# Crop size is your ending image size. Advanced users can modify up to 1024. Default value is 512.\n",
    "\n",
    "Training_Steps = 5200\n",
    "# Number of instance images * 100 (e.g. if you use 30 images, use 3000 steps). Default value 1000.\n",
    "\n",
    "Learning_Rate_Def = 1e-6\n",
    "# Some have good results with 2e-6 and other options. Default value 1e-6.\n",
    "\n",
    "Save_Checkpoint_Every_n_Steps = True\n",
    "# Do you want to save checkpoints as you train? Useful if you want to train for over the recommended limit for best results.\n",
    "\n",
    "Save_Checkpoint_Every = 1300\n",
    "# Minimum 200 steps between each save.\n",
    "# ** NOTE: Remember you only have 20GB space on your Kaggle drive and each CKPT is > 2GB. **\n",
    "\n",
    "Start_saving_from_the_step = 1300\n",
    "# Step at which you would like to START saving (e.g. if this is 500, and Save_Checkpoint_Every is 1000, you will get a save at 500, 1500, 2500, etc.)\n",
    "\n",
    "Train_text_encoder_for = 20\n",
    "# This is the % of the total steps (Training_Steps variable) for which to train the Text Encoder.\n",
    "# If you're training a style, keep it between 10-20 (percent).\n",
    "# If you're training on a person, set it between 50-70 (percent). Reduce this if you can't stylize the person/object (overtrained).\n",
    "# Higher % will give more weight to the instance, it gives stronger results at lower steps count, but harder to stylize.\n",
    "\n",
    "\n",
    "#-------------------------------------------------------- GLOBAL VARIABLES - ERROR OPTIONS ---------------------------------------------------------#\n",
    " \n",
    "Reduce_memory_usage = True\n",
    "# If you're getting memory issues, change this to True (slower speed but memory effecient)\n",
    "\n",
    "Compatibility_Mode = \"\"\n",
    "# Enable only if you're getting model conversion errors for advanced custom CKPTs. True or False.\n",
    "\n",
    "\n",
    "#----------------------------------------------------- GLOBAL VARIABLES - ADVANCED OPTIONS --------------------------------------------------------#\n",
    "#\n",
    "# ** NOTE: If you're unsure about these settings, leave them as-is.\n",
    "\n",
    "fp16 = True\n",
    "# Enable/disable half-precision, disabling it will double the training time and produce 4.7Gb checkpoints.\n",
    "\n",
    "Seed = ''\n",
    "# Leave empty for a random seed.\n",
    "\n",
    "Captionned_instance_images = True\n",
    "# Bool - Learn the caption from your images?\n",
    "\n",
    "Session_Link_optional = \"\"\n",
    "# Import a session from another gdrive\n",
    "# The shared gdrive link must point to the specific session's folder that contains the trained CKPT, remove the intermediary CKPT if any exist.\n",
    "\n",
    "Resume_Training = False\n",
    "# If starting from scratch, this should be False. If you're resuming a training, True.\n",
    "\n",
    "Enable_text_encoder_training = True\n",
    "# If planning to resume training, you must have a total of 10% text encoder training. This can be at the beginning, middle, or end.\n",
    "# For example, you can plan to distribute the text encoder at 15% equally over 3 training sessions in 5%, 5%, 5%, \n",
    "# Or 0%, 0%, 15%, given that 15% will cover the total training steps count (15% of 200 steps is not enough).\n",
    "\n",
    "\n",
    "# Options for using a different model:\n",
    "\n",
    "Path_to_HuggingFace= \"\" #Use the format \"profile/model\" (e.g. runwayml/stable-diffusion-v1-5)\n",
    "\n",
    "CKPT_Path = \"\" #Kaggle path to an uploaded CKPT\n",
    "\n",
    "CKPT_Link = \"\" #A CKPT direct link, huggingface CKPT link, or a shared CKPT from gdrive.\n",
    "\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "#-------------------------------------------------------------------- IMPORTS ---------------------------------------------------------------------#\n",
    "# Now for the code. Don't change anything here:\n",
    "#\n",
    "\n",
    "import os, sys, gc, time\n",
    "\n",
    "from subprocess import getoutput\n",
    "from IPython.display import HTML\n",
    "from IPython.display import clear_output\n",
    "\n",
    "#clear_output()\n",
    "print('\u001b[1;32mInitial setup complete, variables set, please move on to the next cell !')\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "# ** NOTE: YOU MUST RUN THIS CELL FOR THE PROGRAM TO EXECUTE AND REMEMBER YOUR SETTINGS! **\n",
    "#\n",
    "#\n",
    "####################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "mkdir: cannot create directory ‘/usr/local/lib/python3.7’: File exists\n",
      "/workspace/content\n",
      "\u001b[1;32mContent dirs created, please move on to the next cell !\n"
     ]
    }
   ],
   "source": [
    "# Build content directories\n",
    "\n",
    "%cd /\n",
    "!mkdir /workspace/content\n",
    "!mkdir /workspace/content/gdrive\n",
    "!mkdir /workspace/content/gdrive/MyDrive\n",
    "!mkdir /workspace/content/gdrive/MyDrive/Fast-Dreambooth\n",
    "!mkdir /workspace/content/models\n",
    "!mkdir /workspace/content/gdrive/MyDrive/Fast-Dreambooth/Sessions\n",
    "\n",
    "%cd /workspace/content\n",
    "\n",
    "#clear_output()\n",
    "print('\u001b[1;32mContent dirs created, please move on to the next cell !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/content\n",
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
      "Requirement already satisfied: torch==1.12.0+cu113 in /opt/conda/lib/python3.7/site-packages (1.12.0+cu113)\n",
      "Requirement already satisfied: torchvision==0.13.0+cu113 in /opt/conda/lib/python3.7/site-packages (0.13.0+cu113)\n",
      "Requirement already satisfied: torchaudio==0.12.0 in /opt/conda/lib/python3.7/site-packages (0.12.0+cu113)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.12.0+cu113) (4.1.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==0.13.0+cu113) (1.21.5)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision==0.13.0+cu113) (2.27.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.13.0+cu113) (9.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.13.0+cu113) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.13.0+cu113) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.13.0+cu113) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.13.0+cu113) (1.26.8)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Cloning into 'diffusers'...\n",
      "remote: Enumerating objects: 11221, done.\u001b[K\n",
      "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
      "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
      "remote: Total 11221 (delta 18), reused 24 (delta 11), pack-reused 11180\u001b[K\n",
      "Receiving objects: 100% (11221/11221), 8.76 MiB | 13.89 MiB/s, done.\n",
      "Resolving deltas: 100% (7655/7655), done.\n",
      "Collecting git+https://github.com/TheLastBen/diffusers@updt\n",
      "  Cloning https://github.com/TheLastBen/diffusers (to revision updt) to /tmp/pip-req-build-6kkk4bfi\n",
      "  Running command git clone -q https://github.com/TheLastBen/diffusers /tmp/pip-req-build-6kkk4bfi\n",
      "  Running command git checkout -b updt --track origin/updt\n",
      "  Switched to a new branch 'updt'\n",
      "  Branch 'updt' set up to track remote branch 'updt' from 'origin'.\n",
      "  Resolved https://github.com/TheLastBen/diffusers to commit 803d3c597c9bbd5745fbb94a13a42484d5a5ed1b\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from diffusers==0.9.0.dev0) (4.12.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from diffusers==0.9.0.dev0) (2022.10.31)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from diffusers==0.9.0.dev0) (3.6.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from diffusers==0.9.0.dev0) (2.27.1)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from diffusers==0.9.0.dev0) (9.0.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from diffusers==0.9.0.dev0) (1.21.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.10.0 in /opt/conda/lib/python3.7/site-packages (from diffusers==0.9.0.dev0) (0.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.10.0->diffusers==0.9.0.dev0) (4.1.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.10.0->diffusers==0.9.0.dev0) (6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.10.0->diffusers==0.9.0.dev0) (21.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.10.0->diffusers==0.9.0.dev0) (4.63.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.9->huggingface-hub>=0.10.0->diffusers==0.9.0.dev0) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->diffusers==0.9.0.dev0) (3.8.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->diffusers==0.9.0.dev0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->diffusers==0.9.0.dev0) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->diffusers==0.9.0.dev0) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->diffusers==0.9.0.dev0) (3.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: accelerate==0.12.0 in /opt/conda/lib/python3.7/site-packages (0.12.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from accelerate==0.12.0) (5.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from accelerate==0.12.0) (21.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from accelerate==0.12.0) (6.0)\n",
      "Requirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from accelerate==0.12.0) (1.12.0+cu113)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from accelerate==0.12.0) (1.21.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->accelerate==0.12.0) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.4.0->accelerate==0.12.0) (4.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: OmegaConf in /opt/conda/lib/python3.7/site-packages (2.2.3)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /opt/conda/lib/python3.7/site-packages (from OmegaConf) (4.9.3)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /opt/conda/lib/python3.7/site-packages (from OmegaConf) (6.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: wget in /opt/conda/lib/python3.7/site-packages (3.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: open_clip_torch in /opt/conda/lib/python3.7/site-packages (2.7.0)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.7/site-packages (from open_clip_torch) (0.11.0)\n",
      "Requirement already satisfied: ftfy in /opt/conda/lib/python3.7/site-packages (from open_clip_torch) (6.1.1)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from open_clip_torch) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from open_clip_torch) (4.63.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from open_clip_torch) (0.13.0+cu113)\n",
      "Requirement already satisfied: torch>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from open_clip_torch) (1.12.0+cu113)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.9.0->open_clip_torch) (4.1.1)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /opt/conda/lib/python3.7/site-packages (from ftfy->open_clip_torch) (0.2.5)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->open_clip_torch) (4.12.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->open_clip_torch) (3.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->open_clip_torch) (21.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->open_clip_torch) (2.27.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->open_clip_torch) (6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.9->huggingface-hub->open_clip_torch) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub->open_clip_torch) (3.8.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->open_clip_torch) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->open_clip_torch) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->open_clip_torch) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->open_clip_torch) (2.0.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->open_clip_torch) (9.0.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision->open_clip_torch) (1.21.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: torchsde in /opt/conda/lib/python3.7/site-packages (0.2.5)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from torchsde) (1.12.0+cu113)\n",
      "Requirement already satisfied: numpy>=1.19.* in /opt/conda/lib/python3.7/site-packages (from torchsde) (1.21.5)\n",
      "Requirement already satisfied: trampoline>=0.1.2 in /opt/conda/lib/python3.7/site-packages (from torchsde) (0.1.2)\n",
      "Requirement already satisfied: boltons>=20.2.1 in /opt/conda/lib/python3.7/site-packages (from torchsde) (21.0.0)\n",
      "Requirement already satisfied: scipy>=1.5 in /opt/conda/lib/python3.7/site-packages (from torchsde) (1.7.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.6.0->torchsde) (4.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: pytorch_lightning in /opt/conda/lib/python3.7/site-packages (1.8.3.post1)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (0.10.3)\n",
      "Requirement already satisfied: tensorboardX>=2.2 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (2.5.1)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (4.63.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (1.21.5)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (6.0)\n",
      "Requirement already satisfied: lightning-utilities==0.3.* in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (0.3.0)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (2022.11.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (4.1.1)\n",
      "Requirement already satisfied: torch>=1.9.* in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (1.12.0+cu113)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (21.3)\n",
      "Requirement already satisfied: fire in /opt/conda/lib/python3.7/site-packages (from lightning-utilities==0.3.*->pytorch_lightning) (0.4.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.27.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.7/site-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (22.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.8.1)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (0.13.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=17.0->pytorch_lightning) (3.0.9)\n",
      "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /opt/conda/lib/python3.7/site-packages (from tensorboardX>=2.2->pytorch_lightning) (3.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.7/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (3.3)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.7/site-packages (from fire->lightning-utilities==0.3.*->pytorch_lightning) (2.1.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from fire->lightning-utilities==0.3.*->pytorch_lightning) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.26.8)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.7/site-packages (0.11.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (4.63.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (3.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (21.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (2.27.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (4.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.9->huggingface_hub) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface_hub) (3.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (2.0.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: gdown in /opt/conda/lib/python3.7/site-packages (4.5.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from gdown) (4.11.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from gdown) (3.6.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from gdown) (4.63.0)\n",
      "Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.7/site-packages (from gdown) (2.27.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->gdown) (2.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: diffusers[training] in /opt/conda/lib/python3.7/site-packages (0.9.0.dev0)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.7/site-packages (0.12.0)\n",
      "Requirement already satisfied: transformers>=4.21.0 in /opt/conda/lib/python3.7/site-packages (4.24.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from diffusers[training]) (2022.10.31)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from diffusers[training]) (4.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.10.0 in /opt/conda/lib/python3.7/site-packages (from diffusers[training]) (0.11.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from diffusers[training]) (3.6.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from diffusers[training]) (1.21.5)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from diffusers[training]) (9.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from diffusers[training]) (2.27.1)\n",
      "Requirement already satisfied: modelcards>=0.1.4 in /opt/conda/lib/python3.7/site-packages (from diffusers[training]) (0.1.6)\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.7/site-packages (from diffusers[training]) (2.11.0)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (from diffusers[training]) (2.7.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from accelerate) (1.12.0+cu113)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from accelerate) (5.8.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.21.0) (0.13.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.21.0) (4.63.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.10.0->diffusers[training]) (4.1.1)\n",
      "Requirement already satisfied: Jinja2 in /opt/conda/lib/python3.7/site-packages (from modelcards>=0.1.4->diffusers[training]) (3.1.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->accelerate) (3.0.9)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets->diffusers[training]) (0.18.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets->diffusers[training]) (0.70.14)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets->diffusers[training]) (3.1.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets->diffusers[training]) (10.0.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets->diffusers[training]) (3.8.3)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.7/site-packages (from datasets->diffusers[training]) (2022.11.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets->diffusers[training]) (1.3.5)\n",
      "Requirement already satisfied: dill<0.3.7 in /opt/conda/lib/python3.7/site-packages (from datasets->diffusers[training]) (0.3.6)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->diffusers[training]) (2.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->diffusers[training]) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->diffusers[training]) (6.0.2)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->diffusers[training]) (0.13.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->diffusers[training]) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->diffusers[training]) (22.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->diffusers[training]) (1.8.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets->diffusers[training]) (4.0.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->diffusers[training]) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->diffusers[training]) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->diffusers[training]) (2022.6.15)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->diffusers[training]) (3.8.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from Jinja2->modelcards>=0.1.4->diffusers[training]) (2.1.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets->diffusers[training]) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets->diffusers[training]) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets->diffusers[training]) (1.16.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->diffusers[training]) (2.14.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard->diffusers[training]) (2.2.2)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->diffusers[training]) (1.50.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->diffusers[training]) (61.2.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard->diffusers[training]) (0.37.1)\n",
      "Requirement already satisfied: protobuf<4,>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorboard->diffusers[training]) (3.20.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard->diffusers[training]) (1.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->diffusers[training]) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard->diffusers[training]) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard->diffusers[training]) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->diffusers[training]) (1.8.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard->diffusers[training]) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard->diffusers[training]) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard->diffusers[training]) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->diffusers[training]) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->diffusers[training]) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->diffusers[training]) (3.2.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: ftfy in /opt/conda/lib/python3.7/site-packages (6.1.1)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /opt/conda/lib/python3.7/site-packages (from ftfy) (0.2.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.7/site-packages (0.35.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Hit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]      \u001b[0m\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]    \u001b[0m\u001b[33m\n",
      "Get:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]    \u001b[0m\u001b[33m\u001b[33m\n",
      "Fetched 261 kB in 1s (404 kB/s)0m   \u001b[0m                       \u001b[0m33m\u001b[33m\u001b[33m\u001b[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "28 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "/workspace/content\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "git-lfs is already the newest version (2.3.4-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 28 not upgraded.\n",
      "Error: Failed to call git rev-parse --git-dir --show-toplevel: \"fatal: not a git repository (or any parent up to mount point /)\\nStopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\\n\"\n",
      "Git LFS initialized.\n",
      "/\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "rename is already the newest version (0.20-7).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 28 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "zip is already the newest version (3.0-11build1).\n",
      "unzip is already the newest version (6.0-21ubuntu1.2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 28 not upgraded.\n",
      "\u001b[1;32mDependencies installed, please move on to the next cell !\n"
     ]
    }
   ],
   "source": [
    "# Install Diffusers and dependencies\n",
    "\n",
    "%cd /workspace/content\n",
    "\n",
    "!pip install torch==1.12.0+cu113 torchvision==0.13.0+cu113 torchaudio==0.12.0 --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "!git clone --branch updt https://github.com/TheLastBen/diffusers\n",
    "!pip install git+https://github.com/TheLastBen/diffusers@updt\n",
    "!pip install accelerate==0.12.0\n",
    "!pip install OmegaConf\n",
    "!pip install wget\n",
    "!pip install open_clip_torch\n",
    "!pip install torchsde\n",
    "!pip install pytorch_lightning\n",
    "!pip install huggingface_hub\n",
    "!pip install -U --no-cache-dir gdown\n",
    "!pip install diffusers\"[training]\" accelerate \"transformers>=4.21.0\"\n",
    "!pip install ftfy\n",
    "!pip install bitsandbytes\n",
    "!apt update\n",
    "\n",
    "%cd /workspace/content\n",
    "!apt-get install git-lfs\n",
    "!git lfs install\n",
    "\n",
    "%cd /\n",
    "!apt install rename\n",
    "!apt-get install zip unzip\n",
    "\n",
    "#clear_output()\n",
    "print('\u001b[1;32mDependencies installed, please move on to the next cell !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mit seems that your GPU is not supported at the moment\n"
     ]
    }
   ],
   "source": [
    "# Install xformers\n",
    "\n",
    "import wget\n",
    "\n",
    "gpu = ''\n",
    "s = getoutput('nvidia-smi')\n",
    "\n",
    "if 'T4' in s:\n",
    "  gpu = 'T4'\n",
    "elif 'P100' in s:\n",
    "  gpu = 'P100'\n",
    "elif 'V100' in s:\n",
    "  gpu = 'V100'\n",
    "elif 'A100' in s:\n",
    "  gpu = 'A100'\n",
    "\n",
    "if (gpu=='T4'):\n",
    "  %pip install https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/T4/xformers-0.0.13.dev0-py3-none-any.whl --root-user-action=ignore\n",
    "  clear_output()\n",
    "  print('\u001b[1;32mInstalled xformers for your selected GPU to speed up training your model, please move on to the next cell !')\n",
    "  \n",
    "elif (gpu=='P100'):\n",
    "  %pip install https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/P100/xformers-0.0.13.dev0-py3-none-any.whl --root-user-action=ignore\n",
    "  clear_output()\n",
    "  print('\u001b[1;32mInstalled xformers for your selected GPU to speed up training your model, please move on to the next cell !')\n",
    "\n",
    "elif (gpu=='V100'):\n",
    "  %pip install https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/V100/xformers-0.0.13.dev0-py3-none-any.whl --root-user-action=ignore\n",
    "  clear_output()\n",
    "  print('\u001b[1;32mInstalled xformers for your selected GPU to speed up training your model, please move on to the next cell !')\n",
    "\n",
    "elif (gpu=='A100'):\n",
    "  %pip install https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/A100/xformers-0.0.13.dev0-py3-none-any.whl --root-user-action=ignore\n",
    "  clear_output()\n",
    "  print('\u001b[1;32mInstalled xformers for your selected GPU to speed up training your model, please move on to the next cell !')\n",
    "\n",
    "else:\n",
    "    print('\u001b[1;31mit seems that your GPU is not supported at the moment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32mDownloaded SD V2 768 model from StabilityAI on Hugging Face, please move on to the next cell !\n"
     ]
    }
   ],
   "source": [
    "# This cell downloads the Stable Diffusion checkpoint to your working folder.\n",
    "#\n",
    "# ** NOTE: Skip this cell if you are loading a previous session (you don't need to download it more than once)\n",
    "#\n",
    "\n",
    "from IPython.utils import capture\n",
    "\n",
    "#@markdown ---\n",
    "\n",
    "with capture.capture_output() as cap: \n",
    "  %cd /workspace/content/\n",
    "\n",
    "if Model_Version == \"V2-512px\" or Model_Version == \"V2-768px\":\n",
    "  Huggingface_Token = \"\"\n",
    "\n",
    "token = Huggingface_Token\n",
    "\n",
    "\n",
    "def downloadmodel():\n",
    "  \n",
    "  token = Huggingface_Token\n",
    "  \n",
    "  if os.path.exists('/workspace/content/stable-diffusion-v1-5'):\n",
    "    !rm -r /workspace/content/stable-diffusion-v1-5\n",
    "\n",
    "  %cd /workspace/content/\n",
    "  !mkdir /workspace/content/stable-diffusion-v1-5\n",
    "  %cd /workspace/content/stable-diffusion-v1-5\n",
    "\n",
    "  !git init\n",
    "  !git lfs install --system --skip-repo\n",
    "  !git remote add -f origin  \"https://USER:{token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
    "  !git config core.sparsecheckout true\n",
    "  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nmodel_index.json\" > .git/info/sparse-checkout\n",
    "  !git pull origin main\n",
    "\n",
    "  if os.path.exists('/workspace/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
    "    !git clone \"https://USER:{token}@huggingface.co/stabilityai/sd-vae-ft-mse\"\n",
    "    !mv /workspace/content/stable-diffusion-v1-5/sd-vae-ft-mse /workspace/content/stable-diffusion-v1-5/vae\n",
    "    !rm -r /workspace/content/stable-diffusion-v1-5/.git\n",
    "    %cd /workspace/content/stable-diffusion-v1-5    \n",
    "    !rm model_index.json\n",
    "    time.sleep(1)    \n",
    "    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n",
    "    !sed -i 's@\"clip_sample\": false@@g' /workspace/content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n",
    "    !sed -i 's@\"trained_betas\": null,@\"trained_betas\": null@g' /workspace/content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n",
    "    !sed -i 's@\"sample_size\": 256,@\"sample_size\": 512,@g' /workspace/content/stable-diffusion-v1-5/vae/config.json  \n",
    "    %cd /workspace/content/    \n",
    "    \n",
    "    clear_output()\n",
    "    print('\u001b[1;32mDownloaded SDv1.5 from RunwayML on Hugging Face, please move on to the next cell !')\n",
    "  \n",
    "  else:\n",
    "    while not os.path.exists('/workspace/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
    "         print('\u001b[1;31mMake sure you accepted the terms in https://huggingface.co/runwayml/stable-diffusion-v1-5')\n",
    "         time.sleep(5)\n",
    "\n",
    "        \n",
    "def newdownloadmodel():\n",
    "\n",
    "  %cd /workspace/content/ \n",
    "  clear_output()\n",
    "\n",
    "  !mkdir /workspace/content/stable-diffusion-v2-768\n",
    "  %cd /workspace/content/stable-diffusion-v2-768\n",
    "\n",
    "  !git init\n",
    "  !git lfs install --system --skip-repo\n",
    "  !git remote add -f origin  \"https://USER:{token}@huggingface.co/stabilityai/stable-diffusion-2\"\n",
    "  !git config core.sparsecheckout true\n",
    "  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nmodel_index.json\" > .git/info/sparse-checkout\n",
    "  !git pull origin main\n",
    "\n",
    "  clear_output()\n",
    "  print('\u001b[1;32mDownloaded SD V2 768 model from StabilityAI on Hugging Face, please move on to the next cell !')\n",
    "\n",
    "\n",
    "def newdownloadmodelb():\n",
    "\n",
    "  %cd /workspace/content/\n",
    "  clear_output()\n",
    "\n",
    "  !mkdir /workspace/content/stable-diffusion-v2-512\n",
    "  %cd /workspace/content/stable-diffusion-v2-512\n",
    "\n",
    "  !git init\n",
    "  !git lfs install --system --skip-repo\n",
    "  !git remote add -f origin  \"https://USER:{token}@huggingface.co/stabilityai/stable-diffusion-2-base\"\n",
    "  !git config core.sparsecheckout true\n",
    "  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nmodel_index.json\" > .git/info/sparse-checkout\n",
    "  !git pull origin main\n",
    "\n",
    "  clear_output()\n",
    "  print('\u001b[1;32mDownloaded SD V2 512 model from StabilityAI on Hugging Face, please move on to the next cell !')\n",
    "\n",
    "        \n",
    "if Path_to_HuggingFace != \"\":\n",
    "  \n",
    "  if os.path.exists('/workspace/content/stable-diffusion-custom'):\n",
    "    !rm -r /contkaggle/working/contentent/stable-diffusion-custom\n",
    "  clear_output()\n",
    "\n",
    "  %cd /workspace/content/\n",
    "  clear_output()\n",
    "\n",
    "  !mkdir /workspace/content/stable-diffusion-custom\n",
    "  %cd /workspace/content/stable-diffusion-custom\n",
    "\n",
    "  !git init\n",
    "  !git lfs install --system --skip-repo\n",
    "  !git remote add -f origin  \"https://USER:{token}@huggingface.co/{Path_to_HuggingFace}\"\n",
    "  !git config core.sparsecheckout true\n",
    "  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nmodel_index.json\" > .git/info/sparse-checkout\n",
    "  !git pull origin main\n",
    "\n",
    "  if os.path.exists('/workspace/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
    "    !git clone \"https://USER:{token}@huggingface.co/stabilityai/sd-vae-ft-mse\"\n",
    "    !mv /workspace/content/stable-diffusion-custom/sd-vae-ft-mse /workspace/content/stable-diffusion-custom/vae\n",
    "    !rm -r /workspace/content/stable-diffusion-custom/.git\n",
    "    %cd /workspace/content/stable-diffusion-custom\n",
    "    !rm model_index.json\n",
    "    time.sleep(1)\n",
    "    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n",
    "    !sed -i 's@\"clip_sample\": false@@g' /workspace/content/stable-diffusion-custom/scheduler/scheduler_config.json\n",
    "    !sed -i 's@\"trained_betas\": null,@\"trained_betas\": null@g' /workspace/content/stable-diffusion-custom/scheduler/scheduler_config.json\n",
    "    !sed -i 's@\"sample_size\": 256,@\"sample_size\": 512,@g' /workspace/content/stable-diffusion-custom/vae/config.json    \n",
    "    %cd /workspace/content/ \n",
    "    MODEL_NAME = \"/workspace/content/stable-diffusion-custom\"\n",
    "\n",
    "    clear_output()\n",
    "    print('\u001b[1;32mDownloaded your custom model from Hugging Face, please move on to the next cell !')\n",
    "\n",
    "  else:\n",
    "    while not os.path.exists('/workspace/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
    "          print('\u001b[1;32mCheck the link you provided')\n",
    "          time.sleep(5)\n",
    "\n",
    "\n",
    "elif CKPT_Path != \"\":\n",
    "\n",
    "  if os.path.exists('/workspace/content/stable-custom'):\n",
    "    !rm -r /workspace/content/stable-diffusion-custom\n",
    "  \n",
    "  if os.path.exists(str(CKPT_Path)):\n",
    "    !mkdir /workspace/content/stable-diffusion-custom\n",
    "    \n",
    "    with capture.capture_output() as cap:\n",
    "      if Compatibility_Mode:\n",
    "        !wget https://raw.githubusercontent.com/huggingface/diffusers/039958eae55ff0700cfb42a7e72739575ab341f1/scripts/convert_original_stable_diffusion_to_diffusers.py\n",
    "        !python /workspace/content/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path \"$CKPT_Path\" --dump_path /workspace/content/stable-diffusion-custom\n",
    "        !rm /workspace/content/convert_original_stable_diffusion_to_diffusers.py\n",
    "      else:           \n",
    "        !python /workspace/content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path \"$CKPT_Path\" --dump_path /workspace/content/stable-diffusion-custom\n",
    "    \n",
    "    if os.path.exists('/conkaggle/working/contenttent/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
    "      !rm /workspace/content/v1-inference.yaml\n",
    "      clear_output()\n",
    "      MODEL_NAME = \"/workspace/content/stable-diffusion-custom\"\n",
    "      print('\u001b[1;32mCheckpoint converted from custom path, please move on to the next cell !')\n",
    "    else:\n",
    "      !rm /workspace/content/convert_original_stable_diffusion_to_diffusers.py\n",
    "      !rm /workspace/content/v1-inference.yaml\n",
    "      !rm -r /workspace/content/stable-diffusion-custom\n",
    "      while not os.path.exists('/workspace/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
    "        print('\u001b[1;32mConversion error, Insufficient RAM or corrupt CKPT, use a 4GB CKPT instead of 7GB')\n",
    "        time.sleep(5)\n",
    "  \n",
    "  else:\n",
    "    while not os.path.exists(str(CKPT_Path)):\n",
    "       print('\u001b[1;32mWrong path, use the file explorer to copy the path')\n",
    "       time.sleep(5)\n",
    "\n",
    "\n",
    "elif CKPT_Link != \"\":   \n",
    "    \n",
    "    if os.path.exists('/workspace/content/stable-diffusion-custom'):\n",
    "      !rm -r /workspace/content/stable-diffusion-custom   \n",
    "    \n",
    "    !gdown --fuzzy $CKPT_Link -O model.ckpt    \n",
    "    \n",
    "    if os.path.exists('/workspace/content/model.ckpt'):\n",
    "      if os.path.getsize(\"/workspace/content/model.ckpt\") > 1810671599:\n",
    "        !mkdir /workspace/content/stable-diffusion-custom\n",
    "        \n",
    "        with capture.capture_output() as cap: \n",
    "          if Compatibility_Mode:\n",
    "            !wget https://raw.githubusercontent.com/huggingface/diffusers/039958eae55ff0700cfb42a7e72739575ab341f1/scripts/convert_original_stable_diffusion_to_diffusers.py\n",
    "            !python /workspace/content/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path /workspace/content/model.ckpt --dump_path /workspace/content/stable-diffusion-custom\n",
    "            !rm /workspace/content/convert_original_stable_diffusion_to_diffusers.py            \n",
    "          else:           \n",
    "            !python /workspace/content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path /workspace/content/model.ckpt --dump_path /workspace/content/stable-diffusion-custom\n",
    "        \n",
    "        if os.path.exists('/workspace/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
    "          clear_output()\n",
    "          MODEL_NAME = \"/workspace/content/stable-diffusion-custom\"\n",
    "          print('\u001b[1;32mCheckpoint converted from custom path, please move on to the next cell !')\n",
    "          !rm /workspace/content/v1-inference.yaml\n",
    "          !rm /workspace/content/model.ckpt\n",
    "        \n",
    "        else:\n",
    "          if os.path.exists('/workspace/content/v1-inference.yaml'):\n",
    "            !rm /workspace/content/v1-inference.yaml\n",
    "          !rm /workspace/content/convert_original_stable_diffusion_to_diffusers.py\n",
    "          !rm -r /workspace/content/stable-diffusion-custom\n",
    "          !rm /workspace/content/model.ckpt\n",
    "          while not os.path.exists('/workspace/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
    "            print('\u001b[1;32mConversion error, Insufficient RAM or corrupt CKPT, use a 4GB CKPT instead of 7GB')\n",
    "            time.sleep(5)\n",
    "      \n",
    "      else:\n",
    "        while os.path.getsize('/workspace/content/model.ckpt') < 1810671599:\n",
    "           print('\u001b[1;32mWrong link, check that the link is valid')\n",
    "           time.sleep(5)\n",
    "\n",
    "\n",
    "else:\n",
    "  \n",
    "  if Model_Version == \"V2-512px\":\n",
    "    if not os.path.exists('/workspace/content/stable-diffusion-v2-512'):\n",
    "      newdownloadmodelb()\n",
    "      MODEL_NAME=\"/workspace/content/stable-diffusion-v2-512\"\n",
    "    else:\n",
    "      print(\"\u001b[1;32mThe v2-512px model already exist, using this model.\")      \n",
    "  \n",
    "  elif Model_Version == \"V2-768px\":\n",
    "    if not os.path.exists('/workspace/content/stable-diffusion-v2-768'):   \n",
    "      newdownloadmodel()\n",
    "      MODEL_NAME = \"/workspace/content/stable-diffusion-v2-768\"\n",
    "    else:\n",
    "      print(\"\u001b[1;32mThe v2-768px model already exist, using this model.\")\n",
    "\n",
    "  else:\n",
    "    if not os.path.exists('/workspace/content/stable-diffusion-v1-5'):\n",
    "      downloadmodel()\n",
    "      MODEL_NAME = \"/workspace/content/stable-diffusion-v1-5\"\n",
    "    else:\n",
    "      print(\"\u001b[1;32mThe v1.5 model already exist, using this model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32mCreating session...\n",
      "\u001b[1;32mSession created, proceed to uploading instance images\n"
     ]
    }
   ],
   "source": [
    "# Create or load a session\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile\n",
    "\n",
    "try:\n",
    "  MODEL_NAME\n",
    "except:\n",
    "  MODEL_NAME = \"\"\n",
    "  print('\u001b[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n",
    "\n",
    "\n",
    "if PT != \"\":\n",
    "  Captionned_instance_images = False\n",
    "\n",
    "Session_Name = Session_Name.replace(\" \",\"_\")\n",
    "\n",
    "WORKSPACE = '/workspace/content/gdrive/MyDrive/Fast-Dreambooth'\n",
    "\n",
    "\n",
    "if Session_Link_optional != \"\":\n",
    "  print('\u001b[1;32mDownloading session...')\n",
    "\n",
    "with capture.capture_output() as cap:\n",
    "  %cd /workspace/content\n",
    "  \n",
    "  if Session_Link_optional != \"\":\n",
    "    if not os.path.exists(str(WORKSPACE+'/Sessions')):\n",
    "      %mkdir -p $WORKSPACE'/Sessions'\n",
    "      time.sleep(1)\n",
    "    %cd $WORKSPACE'/Sessions'\n",
    "    !gdown --folder --remaining-ok -O $Session_Name $Session_Link_optional\n",
    "    %cd $Session_Name\n",
    "    !rm -r instance_images\n",
    "    !rm -r Regularization_images\n",
    "    !unzip instance_images.zip\n",
    "    !mv *.ckpt $Session_Name\".ckpt\"\n",
    "    %cd /workspace/content\n",
    "\n",
    "\n",
    "INSTANCE_NAME = Session_Name    \n",
    "OUTPUT_DIR = \"/workspace/content/models/\" + Session_Name\n",
    "SESSION_DIR = WORKSPACE + '/Sessions/' + Session_Name\n",
    "INSTANCE_DIR = SESSION_DIR + '/instance_images'\n",
    "MDLPTH = str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')\n",
    "CLASS_DIR = SESSION_DIR + '/Regularization_images'\n",
    "\n",
    "\n",
    "if os.path.exists(str(SESSION_DIR)):\n",
    "  if not os.path.exists(MDLPTH) and '.ckpt' in str([ckpt for ckpt in listdir(SESSION_DIR) if ckpt.split(\".\")[-1]==\"ckpt\"]):  \n",
    "    print('\u001b[1;32mSkipping the intermediary checkpoints.')\n",
    "    # Add intermediate checkpoint feature -- need to refactor TheFastBen Google Colab code for Kaggle\n",
    "\n",
    "\n",
    "if os.path.exists(str(SESSION_DIR)) and not os.path.exists(MDLPTH):\n",
    "  print('\u001b[1;32mLoading session with no previous model, using the original model or the custom downloaded model')\n",
    "  if MODEL_NAME == \"\":\n",
    "    print('\u001b[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n",
    "  else:\n",
    "    print('\u001b[1;32mSession Loaded, proceed to uploading instance images')\n",
    "\n",
    "\n",
    "elif os.path.exists(MDLPTH):\n",
    "  print('\u001b[1;32mSession found, loading the trained model ...')\n",
    "  %mkdir -p \"$OUTPUT_DIR\"\n",
    "  !python /workspace/content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path \"$MDLPTH\" --dump_path \"$OUTPUT_DIR\" --session_dir \"$SESSION_DIR\"\n",
    "  if os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
    "    resume = True    \n",
    "    !rm /workspace/content/v1-inference.yaml\n",
    "    clear_output()\n",
    "    print('\u001b[1;32mSession loaded.')\n",
    "  else:     \n",
    "    !rm /workspace/content/v1-inference.yaml\n",
    "    if not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
    "      print('\u001b[1;31mConversion error, if the error persists, remove the CKPT file from the current session folder')\n",
    "\n",
    "\n",
    "elif not os.path.exists(str(SESSION_DIR)):\n",
    "    %mkdir -p \"$INSTANCE_DIR\"\n",
    "    print('\u001b[1;32mCreating session...')\n",
    "    if MODEL_NAME == \"\":\n",
    "      print('\u001b[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n",
    "    else:\n",
    "      print('\u001b[1;32mSession created, proceed to uploading instance images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32mInstance images copied to working directory, please move on to the next cell !\n"
     ]
    }
   ],
   "source": [
    "# Download images from Google Drive\n",
    "\n",
    "!mkdir /workspace/my\n",
    "%cd /workspace/my\n",
    "\n",
    "!rm -r /workspace/my/*\n",
    "!gdown --fuzzy https://drive.google.com/file/d/1cK0gV8WtByP2Hr39F0mRf2176sb8pHi5/view?usp=sharing -O user_images.zip\n",
    "!unzip user_images.zip\n",
    "!rm user_images.zip\n",
    "\n",
    "for instance_items in os.scandir(os.getcwd()):\n",
    "    if instance_items.is_dir():\n",
    "        INSTANCE_DIR_TMP = instance_items.path\n",
    "\n",
    "os.rename(INSTANCE_DIR_TMP,\"user_images\")\n",
    "\n",
    "%cd /workspace/my/user_images\n",
    "!find . -name \"* *\" -type f | rename 's/ /_/g'\n",
    "\n",
    "del INSTANCE_DIR_TMP\n",
    "gc.collect()\n",
    "\n",
    "clear_output()\n",
    "print('\u001b[1;32mInstance images copied to working directory, please move on to the next cell !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download and initialize regularization images \n",
    "\n",
    "if Model_Version = \"V2-768px\":\n",
    "    if Training_Type.lower() == \"person\":\n",
    "        Num_Class_Images_Def = 1000\n",
    "        %cd $SESSION_DIR\n",
    "        !rm -r $SESSION_DIR/*\n",
    "# NEED ACTUAL LINK        !gdown --fuzzy https://drive.google.com/file/d/1dsfY9SF7992t7cc8O-DY1UYCW6Jn6hKz/view?usp=share_link -O Regz.zip\n",
    "        !unzip Regz.zip\n",
    "        !rm Regz.zip\n",
    "    else:\n",
    "        Num_Class_Images_Def = 1000\n",
    "        %cd $SESSION_DIR\n",
    "        !rm -r $SESSION_DIR/*\n",
    "# NEED ACTUAL LINK          !gdown --fuzzy https://drive.google.com/file/d/1d0KsluHx-ZaYCGThxZMuTxVbor2pROlF/view?usp=share_link -O Regz.zip\n",
    "        !unzip Regz.zip\n",
    "        !rm Regz.zip\n",
    "\n",
    "else:\n",
    "    if Training_Type.lower() == \"person\":\n",
    "        Num_Class_Images_Def = 1000\n",
    "        %cd $SESSION_DIR\n",
    "        !rm -r $SESSION_DIR/*\n",
    "        !gdown --fuzzy https://drive.google.com/file/d/1dsfY9SF7992t7cc8O-DY1UYCW6Jn6hKz/view?usp=share_link -O Regz.zip\n",
    "        !unzip Regz.zip\n",
    "        !rm Regz.zip\n",
    "    else:\n",
    "        Num_Class_Images_Def = 1001\n",
    "        %cd $SESSION_DIR\n",
    "        !rm -r $SESSION_DIR/*\n",
    "        !gdown --fuzzy https://drive.google.com/file/d/1d0KsluHx-ZaYCGThxZMuTxVbor2pROlF/view?usp=share_link -O Regz.zip\n",
    "        !unzip Regz.zip\n",
    "        !rm Regz.zip\n",
    "\n",
    "for reg_items in os.scandir(os.getcwd()):\n",
    "    if reg_items.is_dir():\n",
    "        REG_DIR = reg_items.path\n",
    "\n",
    "os.rename(REG_DIR,\"reg_images\")\n",
    "\n",
    "CLASS_DIR = SESSION_DIR + '/reg_images'\n",
    "\n",
    "os.chdir(CLASS_DIR)\n",
    "!find . -name \"* *\" -type f | rename 's/ /_/g'\n",
    "\n",
    "del REG_DIR\n",
    "gc.collect()\n",
    "\n",
    "clear_output()\n",
    "print('\u001b[1;32mRegularization images initialized, please move on to the next cell !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32mDone, time to start training ! Move on to the next cell !\n",
      "/workspace/content/gdrive/MyDrive/Fast-Dreambooth/Sessions/ilya_768/instance_images/user_images\n",
      "/workspace/content\n"
     ]
    }
   ],
   "source": [
    "# Instance images modifications including crop.\n",
    "#\n",
    "# ** NOTE: EVEN IF NOT CROPPING, THIS CELL MUST BE RUN ** \n",
    "\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "#@markdown ----\n",
    "\n",
    "%cd /workspace/content\n",
    "\n",
    "Remove_existing_instance_images = True #@param{type: 'boolean'}\n",
    "#@markdown - Uncheck the box to keep the existing instance images.\n",
    "\n",
    "if Remove_existing_instance_images:\n",
    "  if os.path.exists(str(INSTANCE_DIR)):\n",
    "    !rm -r \"$INSTANCE_DIR\"\n",
    "\n",
    "if not os.path.exists(str(INSTANCE_DIR)):\n",
    "  %mkdir -p \"$INSTANCE_DIR\"\n",
    "\n",
    "IMAGES_FOLDER_OPTIONAL = \"/workspace/my\" #@param{type: 'string'} this is the working directory for your Kaggle instance images. DO NOT CHANGE.\n",
    "\n",
    "#@markdown - Crop script\n",
    "\n",
    "Crop_size = int(Crop_size)\n",
    "\n",
    "if IMAGES_FOLDER_OPTIONAL != \"\":\n",
    "  if Crop_images:\n",
    "    for filename in tqdm(os.listdir(IMAGES_FOLDER_OPTIONAL), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
    "      extension = filename.split(\".\")[1]\n",
    "      identifier = filename.split(\".\")[0]\n",
    "      new_path_with_file = os.path.join(INSTANCE_DIR, filename)\n",
    "      file = Image.open(IMAGES_FOLDER_OPTIONAL+\"/\"+filename)\n",
    "      width, height = file.size\n",
    "      if file.size != (Crop_size, Crop_size):      \n",
    "        side_length = min(width, height)\n",
    "        left = (width - side_length)/2\n",
    "        top = (height - side_length)/2\n",
    "        right = (width + side_length)/2\n",
    "        bottom = (height + side_length)/2\n",
    "        image = file.crop((left, top, right, bottom))\n",
    "        image = image.resize((Crop_size, Crop_size))\n",
    "        image.save(new_path_with_file, format=\"PNG\", quality = 100)\n",
    "      else:\n",
    "        !cp \"$IMAGES_FOLDER_OPTIONAL/$filename\" \"$INSTANCE_DIR\"\n",
    "\n",
    "  else:\n",
    "    for filename in tqdm(os.listdir(IMAGES_FOLDER_OPTIONAL), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
    "      %cp -r \"$IMAGES_FOLDER_OPTIONAL/$filename\" \"$INSTANCE_DIR\"\n",
    " \n",
    "  print('\\n\u001b[1;32mComplete!')\n",
    "\n",
    "\n",
    "elif IMAGES_FOLDER_OPTIONAL == \"\":\n",
    "  uploaded = files.upload()\n",
    "  if Crop_images:\n",
    "    for filename in tqdm(uploaded.keys(), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
    "      shutil.move(filename, INSTANCE_DIR)\n",
    "      extension = filename.split(\".\")[1]\n",
    "      identifier = filename.split(\".\")[0]\n",
    "      new_path_with_file = os.path.join(INSTANCE_DIR, filename)\n",
    "      file = Image.open(new_path_with_file)\n",
    "      width, height = file.size\n",
    "      if file.size != (Crop_size, Crop_size):        \n",
    "        side_length = min(width, height)\n",
    "        left = (width - side_length)/2\n",
    "        top = (height - side_length)/2\n",
    "        right = (width + side_length)/2\n",
    "        bottom = (height + side_length)/2\n",
    "        image = file.crop((left, top, right, bottom))\n",
    "        image = image.resize((Crop_size, Crop_size))\n",
    "        image.save(new_path_with_file, format=\"PNG\", quality = 100)\n",
    "\n",
    "      else:\n",
    "          image.save(new_path_with_file, format=extension.upper())\n",
    "      clear_output()\n",
    "  else:\n",
    "    for filename in tqdm(uploaded.keys(), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
    "      shutil.move(filename, INSTANCE_DIR)\n",
    "      clear_output()\n",
    "\n",
    "  print('\\n\u001b[1;32mDone!')\n",
    "\n",
    "with capture.capture_output() as cap:\n",
    "  %cd \"$INSTANCE_DIR\"\n",
    "  !find . -name \"* *\" -type f | rename 's/ /-/g'\n",
    "  %cd /content\n",
    "  if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
    "    %rm -r INSTANCE_DIR+\"/.ipynb_checkpoints\"    \n",
    "\n",
    "  %cd $SESSION_DIR\n",
    "  !rm instance_images.zip\n",
    "  !zip -r instance_images instance_images\n",
    "\n",
    "%cd $INSTANCE_DIR\n",
    "\n",
    "for all_dirs in os.scandir(os.getcwd()):\n",
    "    if all_dirs.is_dir():\n",
    "        INSTANCE_DIR = all_dirs.path\n",
    "        \n",
    "del all_dirs\n",
    "gc.collect()\n",
    "\n",
    "clear_output()\n",
    "print('\u001b[1;32mDone, time to start training ! Move on to the next cell !')\n",
    "\n",
    "print(INSTANCE_DIR)\n",
    "\n",
    "%cd /workspace/content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START DREAMBOOTH TRAINING !!\n",
    "\n",
    "import random\n",
    "import ftfy\n",
    "from IPython.display import Javascript\n",
    "\n",
    "while not Resume_Training and MODEL_NAME == \"\":\n",
    "  print('\u001b[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n",
    "  time.sleep(5)\n",
    "\n",
    "\n",
    "MODELT_NAME = MODEL_NAME\n",
    "\n",
    "Resolution = Crop_size\n",
    "\n",
    "Res_Int = int(Resolution)\n",
    "\n",
    "GC = \"\"\n",
    "if Reduce_memory_usage or Resolution != \"512\":\n",
    "  GC = \"--gradient_checkpointing\"\n",
    "\n",
    "if Seed == '' or Seed == '0':\n",
    "  Seed = random.randint(1, 999999)\n",
    "else:\n",
    "  Seed = int(Seed)\n",
    "\n",
    "if fp16:\n",
    "  prec = \"fp16\"\n",
    "else:\n",
    "  prec = \"no\"\n",
    "\n",
    "precision = prec\n",
    "\n",
    "\n",
    "CT = \"\"\n",
    "ClassPromptVar = ''\n",
    "\n",
    "if Class_Token:\n",
    "  CT = Training_Type\n",
    "  ClassPromptVar = '--class_prompt=\"$CT\"'\n",
    "\n",
    "\n",
    "Caption = ''\n",
    "\n",
    "if Captionned_instance_images:\n",
    "  Caption = '--image_captions_filename'\n",
    "  \n",
    "\n",
    "if Resume_Training and os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
    "  MODELT_NAME = OUTPUT_DIR\n",
    "  print('\u001b[1;32mResuming Training...\u001b[0m')\n",
    "\n",
    "elif Resume_Training and not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
    "  print('\u001b[1;31mPrevious model not found, training a new model...\u001b[0m') \n",
    "  MODELT_NAME = MODEL_NAME\n",
    "  while MODEL_NAME == \"\":\n",
    "    print('\u001b[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n",
    "    time.sleep(5)\n",
    "\n",
    "#@markdown ---------------------------\n",
    "\n",
    "\n",
    "#@markdown **************************************************** TEXT ENCODER ****************************************************\n",
    "\n",
    "if Train_text_encoder_for >= 100:\n",
    "  stptxt = Training_Steps\n",
    "elif Train_text_encoder_for == 0:\n",
    "  Enable_text_encoder_training = False\n",
    "  stptxt = 10\n",
    "else:\n",
    "  stptxt = int((Training_Steps*Train_text_encoder_for)/100)\n",
    "\n",
    "if Enable_text_encoder_training:\n",
    "  Textenc=\"--train_text_encoder\"\n",
    "else:\n",
    "  Textenc=\"\"\n",
    "\n",
    "\n",
    "#@markdown **************************************************** CKPT SAVES ***********************************************************\n",
    "\n",
    "# ****************** Dreambooth absolute path fix **********************\n",
    "%cd /workspace/content/diffusers/examples/dreambooth/\n",
    "\n",
    "search_text_pathfix = \"/content\"\n",
    "replace_text_pathfix = \"/workspace/content\"\n",
    "\n",
    "with open(r'train_dreambooth.py', 'r') as file_pathfix:\n",
    "  data_pathfix = file_pathfix.read()\n",
    "  data_pathfix = data_pathfix.replace(search_text_pathfix, replace_text_pathfix)\n",
    "\n",
    "with open(r'train_dreambooth.py', 'w') as file_pathfix:\n",
    "  file_pathfix.write(data_pathfix)\n",
    "\n",
    "search_text_pathfix = \"+inst+\"\n",
    "replace_text_pathfix = \"+ckpt_name+\"\n",
    "\n",
    "with open(r'train_dreambooth.py', 'r') as file_pathfix:\n",
    "  data_pathfix = file_pathfix.read()\n",
    "  data_pathfix = data_pathfix.replace(search_text_pathfix, replace_text_pathfix)\n",
    "\n",
    "with open(r'train_dreambooth.py', 'w') as file_pathfix:\n",
    "  file_pathfix.write(data_pathfix)\n",
    "\n",
    "del search_text_pathfix\n",
    "del replace_text_pathfix\n",
    "del file_pathfix\n",
    "del data_pathfix\n",
    "gc.collect()\n",
    "\n",
    "%cd /workspace/content/\n",
    "\n",
    "\n",
    "# ****************** Back to CKPT saves **********************\n",
    "if Save_Checkpoint_Every == None:\n",
    "  Save_Checkpoint_Every = 1\n",
    "\n",
    "stp = 0\n",
    "\n",
    "if Start_saving_from_the_step == None:\n",
    "  Start_saving_from_the_step = 0\n",
    "\n",
    "if (Start_saving_from_the_step < 200):\n",
    "  Start_saving_from_the_step = Save_Checkpoint_Every\n",
    "\n",
    "stpsv = Start_saving_from_the_step\n",
    "\n",
    "if Save_Checkpoint_Every_n_Steps:\n",
    "  stp = Save_Checkpoint_Every\n",
    "\n",
    "#@markdown ---------------------------\n",
    "\n",
    "\n",
    "#@markdown **************************************************** ACTIVATE TRAINING ***********************************************************\n",
    "\n",
    "def txtenc_train(Caption, stpsv, stp, MODELT_NAME, INSTANCE_DIR, CLASS_DIR, OUTPUT_DIR, PT, CT, Seed, Res_Int, precision, Learning_Rate_Def, Num_Class_Images_Def, Training_Steps):\n",
    "  print('\u001b[1;33mTraining the text encoder with regularization...\u001b[0m')\n",
    "  !accelerate launch /workspace/content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
    "    $Caption \\\n",
    "    --train_text_encoder \\\n",
    "    --dump_only_text_encoder \\\n",
    "    --pretrained_model_name_or_path=\"$MODEL_NAME\" \\\n",
    "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
    "    --class_data_dir=\"$CLASS_DIR\" \\\n",
    "    --output_dir=\"$OUTPUT_DIR\" \\\n",
    "    --with_prior_preservation --prior_loss_weight=1.0 \\\n",
    "    --instance_prompt=\"$PT\" \\\n",
    "    $ClassPromptVar \\\n",
    "    --seed=$Seed \\\n",
    "    --resolution=$Res_Int \\\n",
    "    --mixed_precision=$precision \\\n",
    "    --train_batch_size=1 \\\n",
    "    --gradient_accumulation_steps=1 --gradient_checkpointing \\\n",
    "    --use_8bit_adam \\\n",
    "    --learning_rate=$Learning_Rate_Def \\\n",
    "    --lr_scheduler=\"polynomial\" \\\n",
    "    --lr_warmup_steps=0 \\\n",
    "    --max_train_steps=$Training_Steps \\\n",
    "    --num_class_images=$Num_Class_Images_Def\n",
    "\n",
    "def unet_train(Caption, SESSION_DIR, stpsv, stp, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, CT, Seed, Res_Int, precision, GC, Learning_Rate_Def, Training_Steps):\n",
    "  clear_output()\n",
    "  print('\u001b[1;33mTraining the unet...\u001b[0m')\n",
    "  !accelerate launch /workspace/content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
    "    $Caption \\\n",
    "    --train_only_unet \\\n",
    "    --Session_dir=$SESSION_DIR \\\n",
    "    --save_starting_step=$stpsv \\\n",
    "    --save_n_steps=$stp \\\n",
    "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
    "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
    "    --output_dir=\"$OUTPUT_DIR\" \\\n",
    "    --instance_prompt=\"$PT\" \\\n",
    "    $ClassPromptVar \\\n",
    "    --seed=$Seed \\\n",
    "    --resolution=$Res_Int \\\n",
    "    --mixed_precision=$precision \\\n",
    "    --train_batch_size=1 \\\n",
    "    --gradient_accumulation_steps=1 $GC \\\n",
    "    --use_8bit_adam \\\n",
    "    --learning_rate=$Learning_Rate_Def \\\n",
    "    --lr_scheduler=\"polynomial\" \\\n",
    "    --lr_warmup_steps=10 \\\n",
    "    --max_train_steps=$Training_Steps\n",
    "\n",
    "if Enable_text_encoder_training:\n",
    "  txtenc_train(Caption, stpsv, stp, MODELT_NAME, INSTANCE_DIR, CLASS_DIR, OUTPUT_DIR, PT, CT, Seed, Res_Int, precision, Learning_Rate_Def, Num_Class_Images_Def, Training_Steps=stptxt)\n",
    "  unet_train(Caption, SESSION_DIR, stpsv, stp, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, CT, Seed, Res_Int, precision, GC, Learning_Rate_Def, Training_Steps)\n",
    "else:\n",
    "  !accelerate launch /workspace/content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
    "    $Caption \\\n",
    "    $Textenc \\\n",
    "    --save_starting_step=$stpsv \\\n",
    "    --stop_text_encoder_training=$stptxt \\\n",
    "    --save_n_steps=$stp \\\n",
    "    --Session_dir=$SESSION_DIR \\\n",
    "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
    "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
    "    --output_dir=\"$OUTPUT_DIR\" \\\n",
    "    --instance_prompt=\"$PT\" \\\n",
    "    $ClassPromptVar \\\n",
    "    --seed=$Seed \\\n",
    "    --resolution=$Res_Int \\\n",
    "    --mixed_precision=$precision \\\n",
    "    --train_batch_size=1 \\\n",
    "    --gradient_accumulation_steps=1 $GC \\\n",
    "    --use_8bit_adam \\\n",
    "    --learning_rate=$Learning_Rate_Def \\\n",
    "    --lr_scheduler=\"polynomial\" \\\n",
    "    --lr_warmup_steps=10 \\\n",
    "    --max_train_steps=$Training_Steps\n",
    "\n",
    "\n",
    "if os.path.exists('/workspace/content/models/'+INSTANCE_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
    "  print(\"Almost done ...\")\n",
    "  %cd /workspace/content    \n",
    "  !wget -O convertosd.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertosd.py\n",
    "  clear_output()\n",
    "  if precision==\"no\":\n",
    "    !sed -i '226s@.*@@' /workspace/content/convertosd.py\n",
    "  !sed -i '201s@.*@    model_path = \"{OUTPUT_DIR}\"@' /workspace/content/convertosd.py\n",
    "  !sed -i '202s@.*@    checkpoint_path= \"{SESSION_DIR}/{Session_Name}.ckpt\"@' /workspace/content/convertosd.py\n",
    "  !python /workspace/content/convertosd.py\n",
    "  clear_output()\n",
    "  if os.path.exists(SESSION_DIR+\"/\"+INSTANCE_NAME+'.ckpt'):\n",
    "    if not os.path.exists(str(SESSION_DIR+'/tokenizer')):\n",
    "      !cp -R '/workspace/content/models/'$INSTANCE_NAME'/tokenizer' \"$SESSION_DIR\"\n",
    "    print(\"\u001b[1;32mDONE, the CKPT model is in the sessions folder\")\n",
    "  else:\n",
    "    print(\"\u001b[1;31mSomething went wrong\")\n",
    "    \n",
    "else:\n",
    "  print(\"\u001b[1;31mSomething went wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download your new model\n",
    "\n",
    "from IPython.display import FileLink\n",
    "\n",
    "%cd /kaggle/working\n",
    "clear.output()\n",
    "\n",
    "os.symlink(MDLPTH, 'db_checkpoint.ckpt')\n",
    "print(\"Remember! Your activation prompt is:\",PT,CT)\n",
    "FileLink(r'db_checkpoint.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
